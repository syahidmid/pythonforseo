{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/syahidmid/pythonforseo/blob/main/Python_for_SEO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4cYxRp21roe"
      },
      "source": [
        "# SEO Content Analysis\n",
        "This Python program is designed to make it easy to analyze the structure of articles, internal links, external links, images, and related keywords. It helps you to quickly and efficiently gather important information about the content of your website, which in turn helps to improve your search engine optimization content.\n",
        "\n",
        "# How to use\n",
        "* Run the code to check the focus keyword of a website by inputing the URL, primary keyword and related keywords.\n",
        "* Related keywords should be made in comma delimited values (Example: asuransi mobil, asuransi mobil terbaik). Use https://arraythis.com/ to convert a list of keywords from table to comma delimited values.\n",
        "\n",
        "## To-do list for improvements:\n",
        "\n",
        "\n",
        "\n",
        "*   Can't detect keywords that are attached with punctuation marks like period and comma.\n",
        "*   Seems like the regular expression hasn't been set to differentiate between lowercase and uppercase.\n",
        "* Giving different colors for related keywords. Green if true.\n",
        "* Create function to analyze the top 4 competitor's content on the SERP.\n",
        "* Change the library for the table to Prettytable to make it more attractive and customizable.\n",
        "\n",
        "## Backup version\n",
        "\n",
        "\n",
        "* [January 13 Version](https://www.notion.so/syahidmuhammad/Python-for-SEO-c5ed5187c6b544eab47cfae385f5d0b5): The code is split into several cells so that the program is not run simultaneously.Adding some function to calculate wordcount\n",
        "* [Before January 13 version](https://www.notion.so/syahidmuhammad/Before-January-13-Version-f939040242f94d27b12f485f1949da98): \n",
        "All functions are run simultaneously. The downside is that it is not effective for developing new functions because the code becomes longer and harder to generate by ChatGPT.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoSnIbfWscyw",
        "outputId": "5c1d773a-d33d-4e88-949b-fa83abffa82a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Item                                         | Result                                                                                                                              |\n",
            "|----------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------|\n",
            "| URL                                          | https://lifepal.co.id/media/lampu-sorot-mobil/                                                                                      |\n",
            "| Primary key                                  | lampu sorot mobil                                                                                                                   |\n",
            "| --------------------                         | -----                                                                                                                               |\n",
            "| Heading 1                                    | Lampu Sorot Mobil: Jenisnya dan Etika Menggunakannya                                                                                |\n",
            "| SEO Title                                    | Lampu Sorot Mobil: Jenisnya dan Etika Menggunakannya                                                                                |\n",
            "| Meta Description                             | Lampu sorot mobil memiliki banyak kegunaan terutama sebagai penerangan tambahan. Mana jenis yang cocok untuk mobilmu? Simak disini! |\n",
            "| --------------------                         | -----                                                                                                                               |\n",
            "| SEO Title Compatibility with H1              | True                                                                                                                                |\n",
            "| Primary keyword are used in SEO Tittle       | False                                                                                                                               |\n",
            "| Primary keyword are used in H1               | False                                                                                                                               |\n",
            "| Primary keyword are used in Meta Description | True                                                                                                                                |\n",
            "| Primary keyword are used in First Paragraph  | True                                                                                                                                |\n",
            "| --------------------                         | -----                                                                                                                               |\n",
            "| SEO Title length                             | The SEO title has a length of 52, which is good                                                                                     |\n",
            "| H1 Title length                              | The H1 element has a length of 52, which is good                                                                                    |\n"
          ]
        }
      ],
      "source": [
        "#@title Focus keyword checking { vertical-output: true }\n",
        "#@markdown Identifying the appearance of primary keywords in an article. Use https://arraythis.com/ to convert a list of keywords from table to comma delimited values.\n",
        "url_input = \"https://lifepal.co.id/media/lampu-sorot-mobil/\" #@param {type:\"string\"}\n",
        "keywords_input = \"lampu sorot mobil \" #@param {type:\"string\"}\n",
        "related_keywords_input = \"lampu led bar mobil, lampu sorot adalah, lampu sorot halogen mobil, lampu sorot led, lampu sorot tembak, lampu spotlight adalah, lampu tambahan mobil, lampu tembak halogen, lampu tembak halogen mobil, cahaya lampu sorot, cara membuat lampu sorot jarak jauh, fungsi lampu sorot, harga lampu sorot jarak jauh, jenis lampu sorot, jenis lampu tembak\" #@param {type:\"string\"}\n",
        "related_keywords_volume_input = \"\"  #@param {type:\"string\"}\n",
        "import re\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from tabulate import tabulate\n",
        "from ipywidgets import widgets\n",
        "\n",
        "# URL halaman web yang akan di-scrape\n",
        "url = url_input\n",
        "primary_keyword = keywords_input\n",
        "related_keywords = related_keywords_input\n",
        "related_keywords_volume = related_keywords_volume_input\n",
        "\n",
        "\n",
        "def compare_seo_title_h1(h1, seo_title):\n",
        "    # Membandingkan SEO Title dengan H1\n",
        "    if seo_title.text == h1.text:\n",
        "        return ['SEO Title Compatibility with H1', 'True']\n",
        "    else:\n",
        "        return ['SEO Title Compatibility with H1', 'False']\n",
        "\n",
        "def compare_primary_keyword_seo_title(seo_title, primary_keyword):\n",
        "    # Membandingkan primary keyword dengan SEO Title\n",
        "    if re.search(primary_keyword, seo_title.text, re.IGNORECASE | re.DOTALL):\n",
        "        return ['Primary keyword are used in SEO Tittle', 'True']\n",
        "    else:\n",
        "        return ['Primary keyword are used in SEO Tittle', 'False']\n",
        "\n",
        "def compare_primary_keyword_h1(h1, primary_keyword):\n",
        "    if re.search(primary_keyword, h1.text, re.IGNORECASE | re.DOTALL):\n",
        "        return ['Primary keyword are used in H1', 'True']\n",
        "    else:\n",
        "        return ['Primary keyword are used in H1', 'False']\n",
        "\n",
        "\n",
        "def compare_primary_keyword_meta_description(meta_description, primary_keyword):\n",
        "  # Membandingkan primary keyword dengan meta description\n",
        "  if re.search(primary_keyword, meta_description, re.IGNORECASE | re.DOTALL):\n",
        "        return  ['Primary keyword are used in Meta Description', 'True']\n",
        "  else:\n",
        "        return ['Primary keyword are used in Meta Description','False']\n",
        "\n",
        "def compare_primary_keyword_first_paragraph(first_paragraph, primary_keyword):\n",
        "    # Membandingkan primary keyword dengan paragraf pertama\n",
        "    if re.search(primary_keyword, first_paragraph.text, re.IGNORECASE | re.DOTALL):\n",
        "        return ['Primary keyword are used in First Paragraph', 'True']\n",
        "    else:\n",
        "        return ['Primary keyword are used in First Paragraph', 'False']\n",
        "\n",
        "\n",
        "\n",
        "def count_seo_title(seo_title):\n",
        "    seo_title_length = len(seo_title.text)\n",
        "    if seo_title_length < 50:\n",
        "        return ['SEO Title length', f'The SEO title has a length of {seo_title_length}, which is too short']\n",
        "    elif seo_title_length > 60:\n",
        "        return ['SEO Title length', f'The SEO title has a length of {seo_title_length}, which is too long']\n",
        "    else:\n",
        "        return ['SEO Title length', f'The SEO title has a length of {seo_title_length}, which is good']\n",
        "\n",
        "def count_h1(h1_element):\n",
        "    h1_length = len(h1_element.text)\n",
        "    if h1_length < 50:\n",
        "        return ['H1 Title length', f'The H1 element has a length of {h1_length}, which is too short']\n",
        "    elif h1_length > 60:\n",
        "        return ['H1 Title length', f'TThe H1 element has a length of {h1_length}, which is too long']\n",
        "    else:\n",
        "        return ['H1 Title length', f'The H1 element has a length of {h1_length}, which is good']\n",
        "\n",
        "# Mengirim permintaan ke halaman web dan menyimpan respon dalam variabel 'response'\n",
        "response = requests.get(url)\n",
        "\n",
        "# Mengekstrak HTML dari respon\n",
        "html = response.text\n",
        "\n",
        "# Membuat objek Beautiful Soup dari HTML\n",
        "soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "# Mencari elemen \n",
        "results = []\n",
        "h1_elements = soup.find_all('h1')\n",
        "# add the function in the existing code\n",
        "h1_elements = soup.find_all('h1')\n",
        "if h1_elements:\n",
        "    h1_element = h1_elements[0]\n",
        "    results.append(count_h1(h1_element))\n",
        "else:\n",
        "    results.append(['H1 Title length', 'Not found'])\n",
        "h1_element = soup.find_all('h1')[0]\n",
        "seo_title = soup.find('title')\n",
        "if seo_title:\n",
        "    results.append(count_seo_title(seo_title))\n",
        "else:\n",
        "    results.append(['SEO Title length', 'Not found'])\n",
        "meta = soup.find('meta', attrs={'name': 'description'})\n",
        "meta_description = meta['content']\n",
        "first_paragraph = soup.find('p')\n",
        "\n",
        "headings = soup.find_all(['h1', 'h2', 'h3'])\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "\n",
        "# Menyimpan hasil dalam list\n",
        "results = []\n",
        "for h1 in h1_elements:\n",
        "    results.append(['URL', url])\n",
        "    results.append(['Primary key', primary_keyword])\n",
        "    results.append(['--------------------', '-----'])\n",
        "    results.append(['Heading 1', h1.text])\n",
        "    results.append(['SEO Title', seo_title.text])\n",
        "    results.append(['Meta Description', meta_description])\n",
        "    results.append(['--------------------', '-----'])\n",
        "    results.append(compare_seo_title_h1(h1, seo_title))\n",
        "    results.append(compare_primary_keyword_seo_title(seo_title, primary_keyword))\n",
        "    results.append(compare_primary_keyword_h1(h1_element, primary_keyword))\n",
        "    results.append(compare_primary_keyword_meta_description(meta_description,  primary_keyword))\n",
        "    results.append(compare_primary_keyword_first_paragraph(first_paragraph, primary_keyword))\n",
        "    results.append(['--------------------', '-----'])\n",
        "    results.append(count_seo_title(seo_title))\n",
        "    results.append(count_h1(h1_element))\n",
        "    \n",
        "\n",
        "\n",
        "# Menampilkan hasil dalam tabel\n",
        "print(tabulate(results, headers=['Item', 'Result'], tablefmt='orgtbl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdsEq17XtK6_",
        "outputId": "5867bf4a-1215-4df9-8601-fc750edba041"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| Related Keyword                     | Found in Article   |\n",
            "|-------------------------------------+--------------------|\n",
            "| lampu led bar mobil                 | False              |\n",
            "| lampu sorot adalah                  | False              |\n",
            "| lampu sorot halogen mobil           | False              |\n",
            "| lampu sorot led                     | True               |\n",
            "| lampu sorot tembak                  | False              |\n",
            "| lampu spotlight adalah              | False              |\n",
            "| lampu tambahan mobil                | False              |\n",
            "| lampu tembak halogen                | False              |\n",
            "| lampu tembak halogen mobil          | False              |\n",
            "| cahaya lampu sorot                  | True               |\n",
            "| cara membuat lampu sorot jarak jauh | False              |\n",
            "| fungsi lampu sorot                  | True               |\n",
            "| harga lampu sorot jarak jauh        | False              |\n",
            "| jenis lampu sorot                   | True               |\n",
            "| jenis lampu tembak                  | True               |\n"
          ]
        }
      ],
      "source": [
        "#@title Related keyword checking { vertical-output: true }\n",
        "#@markdown Checking all related keywords given in the Focus keyword checking cell.\n",
        "def check_related_keywords(soup, related_keywords):\n",
        "    related_keywords_result = []\n",
        "    for keyword in related_keywords:\n",
        "        if re.search(keyword, soup.text, re.IGNORECASE | re.DOTALL):\n",
        "            related_keywords_result.append([keyword, True])\n",
        "        else:\n",
        "            related_keywords_result.append([keyword, False])\n",
        "    return related_keywords_result\n",
        "\n",
        "related_keywords_list = related_keywords.split(\",\")\n",
        "related_keywords_result = check_related_keywords(soup, related_keywords_list)\n",
        "print(tabulate(related_keywords_result, headers=['Related Keyword', 'Found in Article'], tablefmt='orgtbl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOiqn4Qwl1Nm",
        "outputId": "0afe3ed4-b650-4ba5-ffd1-058aa278145b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<H1> Jangan Asal Cuci Steam Mobil Sendiri, Ketahui Bahayanya\n",
            "<H2> Keuntungan cuci steam mobil\n",
            "<H2> Bahaya cuci steam mobil sendiri\n",
            "<H3> 1. Mesin mobil\n",
            "<H3> 2. Lapisan anti karat\n",
            "<H3> 3. Sensor kendaraan\n",
            "<H3> 4. Bodi pada kendaraan\n",
            "<H2> Hal yang perlu diperhatikan saat mencuci mobil sendiri\n",
            "<H3> 1. Pilih alat cuci yang sesuai\n",
            "<H3> 2. Pastikan memarkir mobil di tempat yang tepat\n",
            "<H3> 3. Bilas mobil sebelum menggunakan sabun\n",
            "<H3> 4. Perhatikan teknik yang tepat dalam membilas mobil\n",
            "<H2> Rekomendasi mesin cuci steam mobil\n",
            "<H3> 1. Bosch Easy Aquatak 120\n",
            "<H3> 2. Bosch Universal Aquatak 125 High Pressure Cleaner\n",
            "<H3> 3. Karcher K2 Basic Car 900 Watt High Pressure Washer\n",
            "<H3> 4. Multipro HPC 1309L 900 Watt High Pressure Washer\n",
            "<H2> Pentingnya memiliki asuransi kendaraan\n",
            "<H2> FAQ seputar cuci steam mobil\n"
          ]
        }
      ],
      "source": [
        "#@title Get article outline { vertical-output: true }\n",
        "#@markdown Getting the H2 and H3 outline from the url given in the Focus keyword checking cell.\n",
        "def get_all_headings(url):\n",
        " # Mencari semua elemen heading\n",
        " # Inisialisasi list untuk menyimpan heading\n",
        "  all_headings = []\n",
        "\n",
        "  # Perulangan untuk setiap heading\n",
        "  for heading in headings:\n",
        "    # Menambahkan tag sesuai dengan tipe heading\n",
        "    if heading.name == 'h1':\n",
        "      all_headings.append(f'<H1> {heading.text}')\n",
        "    elif heading.name == 'h2':\n",
        "      all_headings.append(f'<H2> {heading.text}')\n",
        "    elif heading.name == 'h3':\n",
        "      all_headings.append(f'<H3> {heading.text}')\n",
        "\n",
        "  # Mengembalikan list heading\n",
        "  return all_headings\n",
        "headings = get_all_headings(url)\n",
        "for heading in headings:\n",
        " print(heading)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "z9LvWC7qAuOb"
      },
      "outputs": [],
      "source": [
        "#@title SERP - Competitor and Search Intent Research\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "def get_all_headings(url):\n",
        "    all_headings = []\n",
        "    # Mengambil konten HTML dari halaman web\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    # Mencari semua elemen heading (H1, H2, dan H3)\n",
        "    headings = soup.find_all(['h1', 'h2', 'h3'])\n",
        "    for heading in headings:\n",
        "        all_headings.append(heading.text)\n",
        "    return all_headings\n",
        "\n",
        "# Input URL kompetitor\n",
        "url_satu_input = \"https://indonesiabaik.id/infografis/mengenal-mlff-bayar-tol-tanpa-harus-berhenti\" #@param {type:\"string\"}\n",
        "url_dua_input = \"https://bpjt.pu.go.id/berita/multi-lane-free-flow-mlff-tingkatkan-efisiensi-sistem-transaksi-nirsentuh-di-jalan-tol\" #@param {type:\"string\"}\n",
        "url_tiga_input = \"https://www.kontan.co.id/tag/multi-lane-free-flow-mlff\" #@param {type:\"string\"}\n",
        "url_empat_input = \"https://news.detik.com/kolom/d-6485010/rencana-penerapan-multi-lane-free-flow-di-jalan-tol\" #@param {type:\"string\"}\n",
        "\n",
        "# Memanggil fungsi untuk setiap URL\n",
        "url_satu = url_satu_input\n",
        "headings_satu = get_all_headings(url_satu)\n",
        "\n",
        "url_dua = url_dua_input\n",
        "headings_dua = get_all_headings(url_dua)\n",
        "\n",
        "url_tiga = url_tiga_input\n",
        "headings_tiga = get_all_headings(url_tiga)\n",
        "\n",
        "url_empat = url_empat_input\n",
        "headings_empat = get_all_headings(url_empat)\n",
        "\n",
        "# Cetak hasil dari setiap URL\n",
        "print(\"Headings from URL 1:\")\n",
        "for heading in headings_satu:\n",
        "    print(heading)\n",
        "\n",
        "print(\"\\nHeadings from URL 2:\")\n",
        "for heading in headings_dua:\n",
        "    print(heading)\n",
        "  \n",
        "print(\"\\nHeadings from URL 3:\")\n",
        "for heading in headings_tiga:\n",
        "    print(heading)\n",
        "\n",
        "print(\"\\nHeadings from URL 4:\")\n",
        "for heading in headings_empat:\n",
        "    print(heading)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUyFBpMsZqts"
      },
      "source": [
        "# Bulk Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "8W1gFIOTUi5l",
        "outputId": "c82c3de5-3421-4513-b7cb-de36a7731200"
      },
      "outputs": [
        {
          "ename": "SSLError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSSLCertVerificationError\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             httplib_response = self._make_request(conn, method, url,\n\u001b[0m\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sock'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# AppEngine might not have  `.sock`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 839\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;31m# Add certificate verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0mconn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m         \u001b[0mhostname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/util/ssl_.py\u001b[0m in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir)\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mHAS_SNI\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mserver_hostname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrap_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mserver_hostname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mserver_hostname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mwrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# ctx._wrap_socket()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         return self.sslsocket_class._create(\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0msock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36m_create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1039\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"do_handshake_on_connect should not be specified for non-blocking sockets\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.8/ssl.py\u001b[0m in \u001b[0;36mdo_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1308\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1309\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_handshake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1310\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSSLCertVerificationError\u001b[0m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# Make the request on the httplib connection object.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m             httplib_response = self._make_request(conn, method, url,\n\u001b[0m\u001b[1;32m    598\u001b[0m                                                   \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout_obj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/urllib3/util/retry.py\u001b[0m in \u001b[0;36mincrement\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnew_retry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_exhausted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 399\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMaxRetryError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_pool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mResponseError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='bpjt.pu.go.id', port=443): Max retries exceeded with url: /berita/multi-lane-free-flow-mlff-tingkatkan-efisiensi-sistem-transaksi-nirsentuh-di-jalan-tol (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSSLError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9aed139a6405>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0murl_dua\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl_dua_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mheadings_dua\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_all_headings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_dua\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0murl_tiga\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0murl_tiga_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-9aed139a6405>\u001b[0m in \u001b[0;36mget_all_headings\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mall_headings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# Mengambil konten HTML dari halaman web\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mpage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;31m# Mencari semua elemen heading (H1, H2, dan H3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'allow_redirects'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'get'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    540\u001b[0m         }\n\u001b[1;32m    541\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 655\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mchunked\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 resp = conn.urlopen(\n\u001b[0m\u001b[1;32m    440\u001b[0m                     \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSSLError\u001b[0m: HTTPSConnectionPool(host='bpjt.pu.go.id', port=443): Max retries exceeded with url: /berita/multi-lane-free-flow-mlff-tingkatkan-efisiensi-sistem-transaksi-nirsentuh-di-jalan-tol (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: unable to get local issuer certificate (_ssl.c:1131)')))"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "#@title SERP - Competitor and Search Intent Research Duplicate\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "\n",
        "def get_all_headings(url):\n",
        "    all_headings = []\n",
        "    # Mengambil konten HTML dari halaman web\n",
        "    page = requests.get(url)\n",
        "    soup = BeautifulSoup(page.content, 'html.parser')\n",
        "    # Mencari semua elemen heading (H1, H2, dan H3)\n",
        "    headings = soup.find_all(['h1', 'h2', 'h3'])\n",
        "    for heading in headings:\n",
        "        all_headings.append(heading.text)\n",
        "    return all_headings\n",
        "\n",
        "# Input URL kompetitor\n",
        "url_satu_input = \"https://indonesiabaik.id/infografis/mengenal-mlff-bayar-tol-tanpa-harus-berhenti\" #@param {type:\"string\"}\n",
        "url_dua_input = \"https://bpjt.pu.go.id/berita/multi-lane-free-flow-mlff-tingkatkan-efisiensi-sistem-transaksi-nirsentuh-di-jalan-tol\" #@param {type:\"string\"}\n",
        "url_tiga_input = \"https://www.kontan.co.id/tag/multi-lane-free-flow-mlff\" #@param {type:\"string\"}\n",
        "url_empat_input = \"https://superyou.co.id/blog/keuangan/apa-itu-autodebet/\" #@param {type:\"string\"}\n",
        "\n",
        "# Memanggil fungsi untuk setiap URL\n",
        "url_satu = url_satu_input\n",
        "headings_satu = get_all_headings(url_satu)\n",
        "\n",
        "url_dua = url_dua_input\n",
        "headings_dua = get_all_headings(url_dua)\n",
        "\n",
        "url_tiga = url_tiga_input\n",
        "headings_tiga = get_all_headings(url_tiga)\n",
        "\n",
        "url_empat = url_empat_input\n",
        "headings_empat = get_all_headings(url_empat)\n",
        "\n",
        "# Membuat tabel hasil\n",
        "data = {'Item': [\"Outline\"] * max_length, \n",
        "        'URL 1': headings_satu if len(headings_satu)>0 else ['-']*max_length, \n",
        "        'URL 2': headings_dua if len(headings_dua)>0 else ['-']*max_length, \n",
        "        'URL 3': headings_tiga if len(headings_tiga)>0 else ['-']*max_length, \n",
        "        'URL 4': headings_empat if len(headings_empat)>0 else ['-']*max_length}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Cetak tabel\n",
        "print(df)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ZkBVkCFran3i"
      },
      "outputs": [],
      "source": [
        "#@title Bulk Schema Validator \n",
        "import requests\n",
        "import csv\n",
        "from bs4 import BeautifulSoup\n",
        "import tabulate as tbl\n",
        "\n",
        "# Membaca file CSV dan mengimpor isinya ke dalam list\n",
        "urls = []\n",
        "primary_keywords = []\n",
        "pic_names = []\n",
        "statuses = []\n",
        "checking_statuses = []\n",
        "\n",
        "with open('/content/Hospital Schema.csv', 'r') as csv_file:\n",
        "  reader = csv.reader(csv_file)\n",
        "  next(reader)  # mengabaikan baris pertama yang merupakan judul kolom\n",
        "  for row in reader:\n",
        "    url = row[0]\n",
        "    primary_keyword = row[1]\n",
        "    pic_name = row[2]\n",
        "    status = row[3]\n",
        "    checking_status = row[4]\n",
        "    urls.append(url)\n",
        "    primary_keywords.append(primary_keyword)\n",
        "    pic_names.append(pic_name)\n",
        "    statuses.append(status)\n",
        "    checking_statuses.append(checking_status)\n",
        "\n",
        "# List untuk menyimpan hasil\n",
        "results = []\n",
        "\n",
        "# Perulangan untuk setiap URL\n",
        "for i, url in enumerate(urls):\n",
        "  # Mengirim permintaan HTTP ke URL dan menyimpan respon dalam variabel response\n",
        "  response = requests.get(url)\n",
        "\n",
        "  # Mengekstrak HTML dari respon\n",
        "  html = response.text\n",
        "\n",
        "  # Membuat objek BeautifulSoup dari HTML\n",
        "  soup = BeautifulSoup(html, 'html.parser')\n",
        "\n",
        "  # Mencari semua tag script\n",
        "  script_tags = soup.find_all('script')\n",
        "\n",
        "  # Bandingkan isi dari setiap tag script dengan sceheme markup hospital yang ditentukan\n",
        "  found = False\n",
        "  for script_tag in script_tags:\n",
        "    if '\"@context\": \"https://schema.org\",\\n        \"@type\": \"Hospital\"' in script_tag.text:\n",
        "      found = True\n",
        "      break\n",
        "\n",
        "  # Tambahkan hasil ke list results\n",
        "  if found:\n",
        "    checking_statuses[i] = 'Hospital Scheme Found'\n",
        "  else:\n",
        "    checking_statuses[i] = 'Hospital Scheme Not Found'\n",
        "  results.append([url, primary_keywords[i], pic_names[i], statuses[i], checking_statuses[i]])\n",
        "\n",
        "  # Menampilkan hasil satu per satu\n",
        "  print(url, primary_keywords[i], pic_names[i], statuses[i], checking_statuses[i])\n",
        "\n",
        "# Menampilkan hasil akhir\n",
        "print(tbl.tabulate(results, headers=['URL', 'Primary Keyword', 'PIC Name', 'Status', 'Checking Status']))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "DhLrW9vMWpyU"
      },
      "outputs": [],
      "source": [
        "#@title find_keywods.py\n",
        "# \n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from prettytable import PrettyTable\n",
        "\n",
        "def search_keyword(url, keyword):\n",
        "  # Mengubah keyword menjadi lower case\n",
        "  keyword = keyword.lower()\n",
        "  \n",
        "  # Mengambil konten halaman web dari URL yang diberikan\n",
        "  page = requests.get(url)\n",
        "  # Mengubah konten halaman web menjadi objek BeautifulSoup\n",
        "  soup = BeautifulSoup(page.content, 'html.parser')\n",
        "  # Mencari element body pada halaman web\n",
        "  body = soup.find('body')\n",
        "  # Mencari keyword pada element body\n",
        "  if keyword in body.text.lower():\n",
        "    # Jika keyword ditemukan, mengembalikan status 'Found'\n",
        "    return 'Found in Paragraph'\n",
        "  # Mencari heading 2 (h2) dan heading 3 (h3) dalam body\n",
        "  headings = body.find_all(['h2', 'h3'])\n",
        "  for heading in headings:\n",
        "    # Mendapatkan teks dari setiap heading\n",
        "    text = heading.get_text()\n",
        "    # Mencari keyword pada teks yang didapatkan\n",
        "    if keyword in text.lower():\n",
        "      # Jika keyword ditemukan, mengembalikan status 'Found in Heading'\n",
        "      return 'Found in Heading'\n",
        "  # Jika keyword tidak ditemukan pada elemen manapun, mengembalikan status 'Not Found'\n",
        "  return 'Not Found'\n",
        "\n",
        "# Meminta input URL dan keyword dari pengguna\n",
        "urls = 'https://lifepal.co.id/media/apa-itu-premi-asuransi/' #@param {type:\"string\"}\n",
        "keyword = 'apa itu premi asuransi '  #@param {type:\"string\"}\n",
        "\n",
        "# Memecah input URL menjadi list\n",
        "urls = urls.strip().split(',')\n",
        "\n",
        "# Membuat tabel baru\n",
        "table = PrettyTable()\n",
        "\n",
        "# Menambahkan kolom pada tabel\n",
        "table.field_names = ['URL', 'Keyword', 'Status']\n",
        "\n",
        "for url in urls:\n",
        "  # Mencari keyword pada setiap URL\n",
        "  status = search_keyword(url, keyword)\n",
        "  # Menambahkan baris baru pada tabel\n",
        "  table.add_row([url, keyword, status])\n",
        "\n",
        "# Menampilkan tabel\n",
        "print(table)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64,
          "referenced_widgets": [
            "ddc6d21f9d2643b399f532c2bc09a648",
            "97ce701d23164614b93e7279de99295d",
            "2cc96d86d71a4614b2ffba6e6c8fb27e"
          ]
        },
        "id": "LvdwmlUfgZYl",
        "outputId": "da520618-261e-4076-93cc-9fa6a474b63e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ddc6d21f9d2643b399f532c2bc09a648",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Textarea(value='', description='Data:', placeholder='Paste data di sini')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#@title Get Organic Keywod from Ahrefs without Download\n",
        "#@markdown Input\n",
        "import ipywidgets as widgets\n",
        "\n",
        "\n",
        "# Membuat widget Textarea\n",
        "data_input = widgets.Textarea(\n",
        "    value='',\n",
        "    placeholder='Paste data di sini',\n",
        "    description='Data:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "# Menampilkan widget Textarea\n",
        "data_input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2sJn9OOgaTv",
        "outputId": "a7fb14ef-43c6-4a56-a57b-d001ce74cfc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Keyword    SF    Volume    KD    CPC    Traffic   \n",
            "\n",
            "\n",
            "Tabel berhasil disimpan ke dalam file hasil_table.csv\n",
            "Daftar keyword berhasil disimpan ke dalam file daftar_keyword.txt\n"
          ]
        }
      ],
      "source": [
        "#@title\n",
        "#@markdown Input\n",
        "import re\n",
        "from tabulate import tabulate\n",
        "\n",
        "# Pola regex untuk mencocokkan data yang diinginkan\n",
        "pattern = re.compile(r'^(.*?)\\n(\\d+)\\n((?:\\d+(?:\\.\\d+)?)K?\\n)(\\d+)\\n([\\d.]+|N/A)\\n(\\d+)$', re.MULTILINE)\n",
        "\n",
        "\n",
        "\n",
        "# Mencari data yang cocok dengan pola\n",
        "match = re.findall(pattern, data_input.value)\n",
        "\n",
        "\n",
        "\n",
        "# Membuat header tabel\n",
        "headers = [\"Keyword\", \"SF\", \"Volume\", \"KD\", \"CPC\", \"Traffic\"]\n",
        "\n",
        "# Membuat list untuk menyimpan data yang cocok dengan pola\n",
        "table_data = []\n",
        "\n",
        "for i in range(len(table_data)):\n",
        "    if 'K' in table_data[i][2]:\n",
        "        table_data[i][2] = float(table_data[i][2].replace('K',''))*1000\n",
        "\n",
        "for m in match:\n",
        "    table_data.append([m[0], m[1], m[2], m[3], m[4], m[5]])\n",
        "\n",
        "# Menampilkan tabel\n",
        "print(tabulate(table_data, headers, tablefmt=\"fancy_grid\"))\n",
        "import csv\n",
        "\n",
        "# Nama file CSV yang akan disimpan\n",
        "filename = \"hasil_table.csv\"\n",
        "\n",
        "# Membuka file CSV dengan mode 'w'\n",
        "with open(filename, 'w') as csvfile:\n",
        "    # Membuat objek writer\n",
        "    writer = csv.writer(csvfile)\n",
        "\n",
        "    # Menulis header tabel ke dalam file CSV\n",
        "    writer.writerow(headers)\n",
        "\n",
        "    # Menulis data tabel ke dalam file CSV\n",
        "    writer.writerows(table_data)\n",
        "\n",
        "print(f\"Tabel berhasil disimpan ke dalam file {filename}\")\n",
        "\n",
        "# Nama file teks yang akan disimpan\n",
        "filename = \"daftar_keyword.txt\"\n",
        "\n",
        "# Membuka file teks dengan mode 'w'\n",
        "with open(filename, 'w') as txtfile:\n",
        "    # Menulis keyword-keyword ke dalam file teks\n",
        "    for data in table_data:\n",
        "        txtfile.write(data[0] + '\\n')\n",
        "\n",
        "print(f\"Daftar keyword berhasil disimpan ke dalam file {filename}\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2cc96d86d71a4614b2ffba6e6c8fb27e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "97ce701d23164614b93e7279de99295d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ddc6d21f9d2643b399f532c2bc09a648": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "TextareaModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "Data:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_97ce701d23164614b93e7279de99295d",
            "placeholder": "Paste data di sini",
            "rows": null,
            "style": "IPY_MODEL_2cc96d86d71a4614b2ffba6e6c8fb27e",
            "value": "blind spot adalah\n3\n1.5K\n0\n0.00\n5\t18\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n4 d ago\n\nblind spot artinya\n4\n300\n0\nN/A\n3.0\t14\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n26 Jan 2023\n\nblindspot artinya\n4\n250\n0\nN/A\n2.0\t15\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n27 Jan 2023\n\nblind artinya\n4\n1.6K\n0\nN/A\n1.0\t26\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n4 d ago\n\nblindspot adalah\n4\n400\n0\nN/A\n1.0\t20\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n24 Jan 2023\n\napa itu blind spot\n5\n200\n0\nN/A\n1.0\t19\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n22 Jan 2023\n\narti blind spot\n6\n300\n0\nN/A\n1.0\t21\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n1 h ago\n\narti spot area\n4\n150\n0\nN/A\n0\t19\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n29 Jan 2023\n\nspion kendaraan memanfaatkan cermin cembung supaya\n4\n100\n0\nN/A\n0\t19\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n26 Jan 2023\n\nblind area adalah\n4\n100\n0\nN/A\n0\t21\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n24 Jan 2023\n\narti blind\n4\n900\n0\n0.00\n0\t26\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n15 h ago\n\nblind spot\n5\n3.6K\n0\nN/A\n0\t36\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n5 h ago\n\napa itu blind\n3\n100\n0\nN/A\n0\t26\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n9 d ago\n\nblin spot\n4\n150\n0\nN/A\n0\t35\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n8 d ago\n\nbland spot\n4\n60\n0\nN/A\n0\t31\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n30 Jan 2023\n\nblink spot\n3\n90\n0\nN/A\n0\t33\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n13 d ago\n\nspion blind spot\n4\n90\n0\n0.04\n0\t36\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n8 d ago\n\nkaca yang ada di tikungan jalan raya menggunakan cermin\n2\n150\n0\nN/A\n0\t46\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n9 d ago\n\nspot artinya\n3\n70\n0\nN/A\n0\t45\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n4 d ago\n\nblind spot mobil\n4\n150\n0\nN/A\n0\t47\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n30 Jan 2023\n\ncar blind spot\n4\n70\n5\nN/A\n0\t86\t\n \nhttps://lifepal.co.id/media/blind-spot/\n\n\nSERP\n27 Jan 2023\n"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}